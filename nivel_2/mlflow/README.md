# üöÄ Taller MLflow - Proyecto de Predicci√≥n de Credit Score

Este proyecto implementa un flujo completo de **MLOps con MLflow**, incluyendo:

- Base de datos PostgreSQL para almacenar datos de entrenamiento y resultados
- MinIO como backend S3 para almacenar artefactos de modelos
- MLflow Tracking Server + UI para gestionar experimentos y modelos
- JupyterLab para entrenar y registrar modelos
- API robusta con FastAPI para servir predicciones en tiempo real
- pgAdmin y MinIO Console como herramientas de administraci√≥n

---

## üì¶ Estructura del Proyecto

```
.
‚îú‚îÄ‚îÄ api/                # C√≥digo de la API FastAPI
‚îÇ   ‚îî‚îÄ‚îÄ main.py
‚îú‚îÄ‚îÄ data/               # Archivos de datos (ej. sample_data.csv)
‚îú‚îÄ‚îÄ jupyterlab/         # Notebooks de entrenamiento
‚îÇ   ‚îî‚îÄ‚îÄ notebook.ipynb
‚îú‚îÄ‚îÄ mlflow/             # Configuraci√≥n de MLflow server
‚îú‚îÄ‚îÄ scripts/            # Scripts auxiliares (ej. load_data.py)
‚îú‚îÄ‚îÄ docker-compose.yml  # Orquestaci√≥n de servicios
‚îú‚îÄ‚îÄ .env                # Variables de entorno
‚îî‚îÄ‚îÄ README.md           # Este archivo
```

---

## ‚öôÔ∏è Requisitos

- Docker y Docker Compose
- Python 3.9+ (solo si quieres correr notebooks localmente)

---

## üîë Variables de Entorno

Archivo `.env`:

```env
# PostgreSQL
POSTGRES_USER=mlflow_user
POSTGRES_PASSWORD=mlflow_pass
POSTGRES_DB=mlflowdb

# MinIO / S3
MINIO_ROOT_USER=minio
MINIO_ROOT_PASSWORD=minio123
MLFLOW_S3_ENDPOINT=http://minio:9000
MLFLOW_ARTIFACT_URI=s3://mlflow-artifacts/

# API / MLflow
MLFLOW_MODEL_NAME=CreditScoreModel
MLFLOW_MODEL_STAGE=None
```

---

## ‚ñ∂Ô∏è Ejecuci√≥n

Levanta todos los servicios:

```bash
docker compose up -d --build
```

Accede a:

- **MLflow UI**: [http://localhost:5000](http://localhost:5000)
- **FastAPI docs**: [http://localhost:8000/docs](http://localhost:8000/docs)
- **JupyterLab**: [http://localhost:8888](http://localhost:8888)
- **pgAdmin**: [http://localhost:5050](http://localhost:5050)
- **MinIO Console**: [http://localhost:9001](http://localhost:9001)

---

## üóÑÔ∏è Carga de Datos

1. Coloca el archivo `sample_data.csv` (con 1000 registros) en `data/`
2. El script `scripts/load_data.py` carga los datos a PostgreSQL:

```bash
docker compose exec jupyterlab python scripts/load_data.py
```

Esto poblar√° la tabla `credit_data` en la base de datos `mlflowdb`.

---

## üß† Entrenamiento de Modelos

1. Abre [JupyterLab](http://localhost:8888)
2. Ejecuta el notebook `jupyterlab/notebook.ipynb`
3. El notebook:
   - Carga los datos desde PostgreSQL
   - Divide en train/val/test
   - Entrena varios modelos con hiperpar√°metros distintos
   - Compara resultados (`r2`, `rmse`, etc.)
   - Registra runs en MLflow
   - Registra el mejor modelo bajo el nombre `CreditScoreModel`

Ejemplo de registro en el notebook:

```python
mlflow.sklearn.log_model(
    sk_model=model,
    artifact_path="model",
    registered_model_name="CreditScoreModel"
)
```

---

## üåê API de Predicci√≥n

La API `FastAPI` carga el modelo registrado desde MLflow y expone endpoints REST.

### Endpoints principales

- `POST /predict` ‚Üí Predice credit score
- `GET /health` ‚Üí Verifica que el modelo est√© cargado
- `GET /info` ‚Üí Configuraci√≥n de la API y modelo
- `GET /experiments` ‚Üí Lista experimentos
- `GET /experiments/{experiment_name}/best_run` ‚Üí Mejor run de un experimento
- `GET /runs/{run_id}` ‚Üí Detalles de un run
- `GET /model/latest` ‚Üí Descarga el modelo

### Ejemplo de petici√≥n

```bash
curl -X POST "http://localhost:8000/predict"   -H "Content-Type: application/json"   -d '{
    "age": 35,
    "income": 85000,
    "education_level": "Master"
  }'
```

Respuesta:

```json
{
  "credit_score": 702.15
}
```

---

## üß™ Obtener el mejor modelo desde MLflow

Ejemplo en un notebook o script:

```python
from mlflow.tracking import MlflowClient

client = MlflowClient()
experiment = client.get_experiment_by_name("CreditScorePrediction")

runs = client.search_runs(
    experiment_ids=[experiment.experiment_id],
    order_by=["metrics.r2 DESC"],
)

best_run = runs[0]
print("Best run ID:", best_run.info.run_id)
print("Metrics:", best_run.data.metrics)
```

---

## üõ†Ô∏è Debug & Tips

- Si la API lanza `RESOURCE_DOES_NOT_EXIST`, significa que a√∫n no registraste un modelo con el nombre esperado (`CreditScoreModel`).
- Si falla con `Unable to locate credentials`, revisa las variables de entorno `AWS_ACCESS_KEY_ID`, `AWS_SECRET_ACCESS_KEY`, y `MLFLOW_S3_ENDPOINT_URL` en el servicio `api`.
- Para borrar datos y empezar de cero:
  ```bash
  docker compose down -v
  ```

---

## üõ†Ô∏è Uso del Makefile

Este proyecto incluye un **Makefile** que simplifica la ejecuci√≥n de los comandos m√°s comunes de Docker, carga de datos y pruebas de la API.  
En lugar de recordar comandos largos, puedes usar accesos directos con `make`.

### üìã Principales comandos

- **Levantar servicios**
  ```bash
  make up
  ```
  Inicia todos los contenedores definidos en `docker-compose.yml`.

- **Reconstruir im√°genes**
  ```bash
  make build
  ```

- **Detener servicios**
  ```bash
  make down
  ```

- **Ver logs en tiempo real**
  ```bash
  make logs
  ```

- **Reiniciar todo**
  ```bash
  make restart
  ```

- **Resetear base de datos**
  ```bash
  make reset-db
  ```
  Elimina los vol√∫menes de PostgreSQL y vuelve a crear la base limpia.

- **Resetear almacenamiento MinIO**
  ```bash
  make reset-minio
  ```
  Borra el volumen usado por MinIO.

---

### üìä Carga de datos

El comando `load-data` carga autom√°ticamente el archivo `data/sample_data.csv` en la base de datos PostgreSQL:

```bash
make load-data
```

Esto ejecuta el script `scripts/load_data.py` dentro del contenedor `jupyterlab`.

---

### üßë‚Äçüíª Accesos r√°pidos para desarrollo

- **Abrir JupyterLab**
  ```bash
  make notebook
  ```
  (abre en tu navegador `http://localhost:8888`).

- **Abrir API Docs (Swagger)**
  ```bash
  make api
  ```
  (abre en tu navegador `http://localhost:8000/docs`).

- **Listar notebooks activos**
  ```bash
  make notebook-list
  ```

---

### üåê Probar la API

Ejecuta un request de prueba contra el endpoint `/predict`:

```bash
make test-api
```

Ejemplo de respuesta:

```json
{"credit_score": 710.42}
```

---

### üßπ Limpieza

Para detener todo, borrar vol√∫menes y liberar espacio:

```bash
make clean
```

---

### ‚ö†Ô∏è Nota Importante sobre el uso de la API

Antes de poder usar la API de predicci√≥n (`/predict`), es necesario:

1. **Ejecutar un experimento desde JupyterLab**  
   - Abre [http://localhost:8888](http://localhost:8888)
   - Corre el notebook `jupyterlab/notebook.ipynb`
   - Esto entrenar√° varios modelos y registrar√° el mejor en MLflow con el nombre `CreditScoreModel`.

2. **Confirmar que el modelo est√° registrado en MLflow**  
   - Ingresa a la UI de MLflow: [http://localhost:5000](http://localhost:5000)
   - Verifica que existe un modelo registrado como `CreditScoreModel` en la pesta√±a **Models**.

3. **Reci√©n entonces usar la API**  
   Una vez registrado, la API podr√° cargar el modelo autom√°ticamente y `/predict` funcionar√° sin errores.

> Si intentas llamar la API sin haber corrido antes el experimento y registrado el modelo, obtendr√°s un error tipo:  
> `RESOURCE_DOES_NOT_EXIST: Registered Model with name=CreditScoreModel not found`

## üß™ Flujo de Entrenamiento y Registro de Modelos

En esta soluci√≥n se implement√≥ un flujo completo de **entrenamiento, experimentaci√≥n y registro de modelos con MLflow**, asegurando buenas pr√°cticas de MLOps.  

### üîπ 1. Notebook de Entrenamiento
Se cre√≥ un notebook (`jupyterlab/notebook.ipynb`) que:
- Conecta a la base de datos PostgreSQL (`mlflowdb`) para leer los datos.
- Preprocesa las variables y asegura que los datos procesados se escriban nuevamente en la base de datos.
- Ejecuta m√∫ltiples experimentos de entrenamiento (al menos **20 corridas**), variando hiperpar√°metros como:
  - N√∫mero de √°rboles y profundidad en RandomForest
  - Diferentes regresores lineales
  - Otras configuraciones de modelos
- Registra cada corrida en **MLflow Tracking Server**, incluyendo:
  - Hiperpar√°metros
  - M√©tricas (`r2`, `rmse`, etc.)
  - Artefactos generados (gr√°ficos, modelos serializados, etc.)

### üîπ 2. Persistencia de Datos
- Los **datos crudos** se cargan desde `sample_data.csv` a PostgreSQL con el script `scripts/load_data.py`.
- Los **datos procesados** (ya con transformaciones como one-hot encoding) tambi√©n se almacenan en PostgreSQL para garantizar reproducibilidad.

### üîπ 3. Registro de Modelos en MLflow
- Una vez completados los experimentos, se selecciona el mejor modelo seg√∫n m√©tricas de validaci√≥n.
- Este modelo se registra en el **MLflow Model Registry** bajo el nombre `CreditScoreModel`.
- Ejemplo del registro en el notebook:

```python
import mlflow.sklearn

mlflow.sklearn.log_model(
    sk_model=model,
    artifact_path="model",
    registered_model_name="CreditScoreModel"
)
```

### üîπ 4. Integraci√≥n con la API
- La API FastAPI (`api/main.py`) carga autom√°ticamente el modelo registrado en MLflow.
- Esto garantiza que cualquier cliente pueda consumir predicciones de manera consistente sin necesidad de reentrenar.
- Si no existe un modelo registrado, la API retornar√° un error informando que primero se debe entrenar y registrar el modelo.

---
