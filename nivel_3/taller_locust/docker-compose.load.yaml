version: '3.8'

services:
  # API de inferencia (target de las pruebas)
  api:
    image: sefanchil/ml-inference-api:latest
    # Para usar imagen de DockerHub, reemplaza con:
    # image: tu-usuario/ml-inference-api:latest
    # container_name: ml-api-load-test  # Comentado para permitir escalado
    expose:
      - "8000"
    environment:
      - PORT=8000
    networks:
      - load-test-network
    deploy:
      resources:
        limits:
          cpus: '1.0'      # AJUSTAR según experimentos
          memory: 1024M     # AJUSTAR según experimentos
        reservations:
          cpus: '0.5'
          memory: 512M
    healthcheck:
      test: ["CMD-SHELL", "python -c 'import requests; requests.get(\"http://localhost:8000/health\")' || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 10s

  # Locust Master (coordina las pruebas)
  locust-master:
    image: locustio/locust:2.17.0
    container_name: locust-master
    ports:
      - "8089:8089"    # Web UI
      - "5557:5557"    # Para workers
    volumes:
      - ./locust:/mnt/locust
    command: >
      -f /mnt/locust/locustfile.py
      --master
      --expect-workers=2
      --host=http://api:8000
    networks:
      - load-test-network
    depends_on:
      api:
        condition: service_healthy
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 512M

  # Locust Worker 1
  locust-worker-1:
    image: locustio/locust:2.17.0
    container_name: locust-worker-1
    volumes:
      - ./locust:/mnt/locust
    command: >
      -f /mnt/locust/locustfile.py
      --worker
      --master-host=locust-master
    networks:
      - load-test-network
    depends_on:
      - locust-master
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 512M

  # Locust Worker 2
  locust-worker-2:
    image: locustio/locust:2.17.0
    container_name: locust-worker-2
    volumes:
      - ./locust:/mnt/locust
    command: >
      -f /mnt/locust/locustfile.py
      --worker
      --master-host=locust-master
    networks:
      - load-test-network
    depends_on:
      - locust-master
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 512M

networks:
  load-test-network:
    driver: bridge

# INSTRUCCIONES DE USO:
#
# 1. Iniciar las pruebas:
#    docker-compose -f docker-compose.load.yaml up
#
# 2. Abrir interfaz web de Locust:
#    http://localhost:8089
#
# 3. Configurar prueba en la web UI:
#    - Number of users: 10000
#    - Spawn rate: 500
#    - Host: http://api:8000 (ya configurado)
#
# 4. Ver estadísticas en tiempo real en la interfaz
#
# 5. Para pruebas headless (sin UI):
#    docker-compose -f docker-compose.load.yaml run --rm locust-master \
#      -f /mnt/locust/locustfile.py \
#      --host=http://api:8000 \
#      --users=10000 \
#      --spawn-rate=500 \
#      --run-time=5m \
#      --headless \
#      --html=/mnt/locust/report.html
#
# 6. Detener pruebas:
#    docker-compose -f docker-compose.load.yaml down
#
# ESCALADO DE RÉPLICAS DE LA API:
#
# Para escalar a múltiples réplicas (sin Nginx):
#    docker-compose -f docker-compose.load.yaml up --scale api=2 -d
#    docker-compose -f docker-compose.load.yaml up --scale api=3 -d
#
# Docker DNS distribuirá las peticiones automáticamente (round-robin)
# entre todas las réplicas cuando Locust accede a http://api:8000
#
# Verificar réplicas:
#    docker ps | grep api
#    docker stats
#
# Recursos totales con múltiples réplicas:
#    2 réplicas = 2.0 CPU, 2GB RAM
#    3 réplicas = 3.0 CPU, 3GB RAM

