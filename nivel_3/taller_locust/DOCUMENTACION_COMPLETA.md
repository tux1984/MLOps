# üìö Taller MLOps: API de Inferencia con FastAPI, Docker y Pruebas de Carga


**Equipo:** MLOps Equipo 8  
**Fecha:** Octubre 2025  
**Objetivo:** Implementar y optimizar una API de inferencia ML con pruebas de carga y escalamiento horizontal

---

## üìë Tabla de Contenidos

1. [Resumen Ejecutivo](#-resumen-ejecutivo)
2. [Objetivos del Taller](#-objetivos-del-taller)
3. [Arquitectura y Tecnolog√≠as](#-arquitectura-y-tecnolog√≠as)
4. [Setup del Proyecto](#-setup-del-proyecto)
5. [Experimentos Realizados](#-experimentos-realizados)
6. [An√°lisis de Resultados](#-an√°lisis-de-resultados)
7. [Conclusiones y Respuestas](#-conclusiones-y-respuestas)
8. [Gu√≠a de Uso R√°pida](#-gu√≠a-de-uso-r√°pida)
9. [Troubleshooting](#-troubleshooting)

---

## üéØ Resumen Ejecutivo

Este proyecto implementa una **API REST de inferencia ML** usando FastAPI, containerizada con Docker, y sometida a pruebas de carga exhaustivas usando Locust. Se realizaron **3 iteraciones experimentales** para encontrar la configuraci√≥n √≥ptima de recursos y estrategia de escalamiento.

### Logros Principales

‚úÖ **API funcional** con modelo de clasificaci√≥n Iris (Random Forest)  
‚úÖ **Imagen Docker optimizada** publicada en DockerHub  
‚úÖ **Pruebas de carga** soportando hasta 10,000 usuarios simult√°neos  
‚úÖ **Escalamiento horizontal** implementado sin Nginx  
‚úÖ **Reducci√≥n de errores** de 14.9% ‚Üí 6.1% ‚Üí 0.24%  
‚úÖ **Mejora de throughput** de 288 RPS ‚Üí 574 RPS ‚Üí 1015 RPS  

### Configuraci√≥n √ìptima Encontrada

```yaml
R√©plicas: 2
CPU por r√©plica: 1.0 core
Memoria por r√©plica: 1024MB (1GB)
Total recursos: 2.0 cores, 2GB RAM

Resultados:
- RPS: 1015 req/s (3.5x mejor que config inicial)
- Latencia P95: 900ms (37x mejor)
- Tasa de error: 0.24% (62x mejor)
```

---

## üéì Objetivos del Taller

### Requisitos Funcionales

1. ‚úÖ Crear imagen Docker con API FastAPI para inferencia ML
2. ‚úÖ Consumir modelo entrenado (simulando MLflow)
3. ‚úÖ Publicar imagen en DockerHub
4. ‚úÖ Crear docker-compose para despliegue de la API
5. ‚úÖ Crear docker-compose para pruebas de carga con Locust
6. ‚úÖ Limitar recursos al m√≠nimo para soportar 10,000 usuarios (500/s spawn rate)

### Requisitos de Rendimiento

- **Usuarios simult√°neos:** 10,000
- **Spawn rate:** 500 usuarios/segundo
- **Tasa de error objetivo:** < 1%
- **Latencia P95 objetivo:** < 1,000ms

### Preguntas a Responder

1. ¬øCu√°les son los recursos m√≠nimos necesarios?
2. ¬øEs posible reducir recursos con m√∫ltiples r√©plicas?
3. ¬øCu√°l es la mayor cantidad de peticiones soportadas?
4. ¬øQu√© diferencia hay entre una o m√∫ltiples instancias?

---

## üèóÔ∏è Arquitectura y Tecnolog√≠as

### Stack Tecnol√≥gico

**Backend & API:**
- FastAPI 0.115.0
- Uvicorn 0.32.0
- Pydantic 2.9.2

**Machine Learning:**
- scikit-learn 1.5.2
- numpy 2.1.2
- joblib 1.4.2
- Modelo: Random Forest Classifier (Iris Dataset)

**Containerizaci√≥n:**
- Docker
- Docker Compose
- Python 3.11 slim (imagen base)

**Pruebas de Carga:**
- Locust 2.17.0
- Arquitectura Master-Worker (1 master + 2 workers)

### Estructura del Proyecto

```
taller_locust/
‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îú‚îÄ‚îÄ app.py              # Aplicaci√≥n FastAPI
‚îÇ   ‚îú‚îÄ‚îÄ model.py            # Gestor del modelo ML
‚îÇ   ‚îú‚îÄ‚îÄ train_model.py      # Script de entrenamiento
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt    # Dependencias
‚îÇ   ‚îî‚îÄ‚îÄ __init__.py         # Package marker
‚îú‚îÄ‚îÄ model/
‚îÇ   ‚îú‚îÄ‚îÄ model.pkl          # Modelo entrenado (175KB)
‚îÇ   ‚îî‚îÄ‚îÄ metadata.pkl       # Metadata del modelo
‚îú‚îÄ‚îÄ locust/
‚îÇ   ‚îú‚îÄ‚îÄ locustfile.py      # Scripts de pruebas
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt   # Dependencias
‚îú‚îÄ‚îÄ Dockerfile              # Imagen de la API
‚îú‚îÄ‚îÄ docker-compose.api.yaml     # Despliegue desarrollo
‚îú‚îÄ‚îÄ docker-compose.load.yaml    # Ambiente pruebas carga
‚îú‚îÄ‚îÄ Makefile               # Comandos automatizados
‚îî‚îÄ‚îÄ DOCUMENTACION_COMPLETA.md  # Este archivo
```

### Endpoints de la API

| Endpoint | M√©todo | Descripci√≥n |
|----------|--------|-------------|
| `/` | GET | Health check b√°sico |
| `/health` | GET | Health check detallado con metadata |
| `/predict` | POST | Inferencia del modelo ML |
| `/metrics` | GET | M√©tricas del modelo |
| `/docs` | GET | Documentaci√≥n Swagger |

---

## üöÄ Setup del Proyecto

### Requisitos Previos

- Python 3.11+ (probado con 3.13)
- Docker & Docker Compose
- 4GB RAM disponibles para experimentos

### Instalaci√≥n y Setup

```bash
# 1. Clonar/acceder al proyecto
cd taller_locust

# 2. Crear entorno virtual
make venv
# o: python3 -m venv .venv

# 3. Activar entorno virtual
source .venv/bin/activate

# 4. Instalar dependencias
make install-deps

# 5. Entrenar modelo
make train

# 6. Construir imagen Docker
make build

# 7. Publicar en DockerHub (opcional)
docker login
make push DOCKER_USER=tu-usuario
```


## üß™ Experimentos Realizados

Se realizaron **3 iteraciones experimentales** con configuraciones progresivamente optimizadas.

### Configuraci√≥n de Pruebas

**Par√°metros constantes:**
- Usuarios totales: 10,000
- Spawn rate: 500 usuarios/segundo
- Duraci√≥n: ~2 minutos por prueba
- Locust: 1 master + 2 workers

---

### üìä Experimento 1: Configuraci√≥n Base (1 R√©plica)

**Objetivo:** Establecer baseline de rendimiento con recursos m√≠nimos iniciales

#### Configuraci√≥n
```yaml
R√©plicas: 1
CPU: 0.5 cores
Memoria: 512MB
```

#### Resultados Detallados

| Endpoint | Requests | Failures | Failure % | RPS | P50 | P95 | P99 |
|----------|----------|----------|-----------|-----|-----|-----|-----|
| GET / | 628 | 39 | 6.2% | 5.2 | 790ms | 15s | 28s |
| GET /health | 2,810 | 1,384 | 49.3% | 23.5 | 16s | 69s | 81s |
| POST /predict | 31,028 | 3,720 | 12.0% | 259.1 | 810ms | 28s | 68s |
| **Agregado** | **34,466** | **5,143** | **14.9%** | **287.8** | **820ms** | **30s** | **69s** |

#### Errores Encontrados

| Error | Endpoint | Ocurrencias | % |
|-------|----------|-------------|---|
| ConnectionResetError | POST /predict | 2,867 | 55.7% |
| ConnectionResetError | GET /health | 1,235 | 24.0% |
| CatchResponseError (status 0) | POST /predict | 430 | 8.4% |
| ConnectTimeoutError | POST /predict | 423 | 8.2% |
| ConnectTimeoutError | GET /health | 149 | 2.9% |

#### An√°lisis

üî¥ **FALLIDO - Recursos Insuficientes**

- ‚ùå Tasa de error: 14.9% (objetivo: <1%)
- ‚ùå Latencia P95: 30,000ms (objetivo: <1,000ms)
- ‚ùå Latencia P99: 69,000ms (inaceptable)
- ‚ö†Ô∏è 55.7% de errores por conexiones reseteadas
- ‚ö†Ô∏è Contenedor al l√≠mite de recursos

**Conclusi√≥n:** 0.5 CPU + 512MB es completamente insuficiente para la carga requerida.

---

### üìä Experimento 2: Recursos Incrementados (1 R√©plica)

**Objetivo:** Encontrar recursos m√≠nimos para 1 r√©plica que soporte la carga

#### Configuraci√≥n
```yaml
R√©plicas: 1
CPU: 1.0 cores (‚Üë 100%)
Memoria: 1024MB / 1GB (‚Üë 100%)
```

#### Resultados Detallados

| Endpoint | Requests | Failures | Failure % | RPS | P50 | P95 | P99 |
|----------|----------|----------|-----------|-----|-----|-----|-----|
| GET / | 1,425 | 35 | 2.5% | 11.9 | 420ms | 760ms | 25s |
| GET /health | 4,581 | 1,265 | 27.6% | 38.3 | 550ms | 77s | 112s |
| POST /predict | 62,676 | 2,901 | 4.6% | 524.1 | 390ms | 940ms | 38s |
| **Agregado** | **68,682** | **4,201** | **6.1%** | **574.3** | **400ms** | **17s** | **55s** |

#### Errores Encontrados

| Error | Endpoint | Ocurrencias | % |
|-------|----------|-------------|---|
| ConnectionResetError | POST /predict | 2,588 | 61.6% |
| ConnectionResetError | GET /health | 1,265 | 30.1% |
| CatchResponseError (status 0) | POST /predict | 287 | 6.8% |
| ConnectTimeoutError | POST /predict | 26 | 0.6% |
| ConnectionResetError | GET / | 35 | 0.8% |

#### Mejoras vs Experimento 1

| M√©trica | Exp 1 | Exp 2 | Mejora |
|---------|-------|-------|--------|
| RPS | 287.8 | 574.3 | **+99.5%** ‚¨ÜÔ∏è |
| Tasa de error | 14.9% | 6.1% | **-59.1%** ‚¨áÔ∏è |
| Latencia P50 | 820ms | 400ms | **-51.2%** ‚¨áÔ∏è |
| Total Requests | 34,466 | 68,682 | **+99.3%** ‚¨ÜÔ∏è |

#### An√°lisis

üü° **MEJORADO - Pero A√∫n Insuficiente**

- üü° Tasa de error: 6.1% (objetivo: <1%) - **Mejor pero no suficiente**
- ‚úÖ Latencia P50: 400ms (excelente)
- ‚ùå Latencia P95: 17,000ms (a√∫n muy alta)
- ‚¨ÜÔ∏è RPS duplicado: de 288 a 574 req/s
- ‚ö†Ô∏è Endpoint /health sigue teniendo 27.6% de errores
- ‚ö†Ô∏è A√∫n hay 4,201 conexiones reseteadas

**Conclusi√≥n:** Duplicar recursos mejora significativamente pero no es suficiente. Se requiere escalamiento horizontal.

---

### üìä Experimento 3: Escalamiento Horizontal (2 R√©plicas)

**Objetivo:** Evaluar beneficio de m√∫ltiples r√©plicas vs una instancia m√°s grande

#### Configuraci√≥n
```yaml
R√©plicas: 2 (‚Üë 100%)
CPU por r√©plica: 1.0 cores
Memoria por r√©plica: 1024MB
Total: 2.0 cores, 2GB RAM
```

#### Resultados Detallados

| Endpoint | Requests | Failures | Failure % | RPS | P50 | P95 | P99 |
|----------|----------|----------|-----------|-----|-----|-----|-----|
| GET / | 2,450 | 0 | 0.0% | 20.5 | 530ms | 910ms | 1,100ms |
| GET /health | 5,936 | 172 | 2.9% | 49.6 | 550ms | 60s | 107s |
| POST /predict | 113,150 | 123 | 0.11% | 945.2 | 520ms | 890ms | 1,000ms |
| **Agregado** | **121,536** | **295** | **0.24%** | **1,015.3** | **520ms** | **900ms** | **1,100ms** |

#### Errores Encontrados

| Error | Endpoint | Ocurrencias | % |
|-------|----------|-------------|---|
| ConnectionResetError | GET /health | 172 | 58.3% |
| ConnectionResetError | POST /predict | 123 | 41.7% |

#### Comparaci√≥n con Configuraciones Anteriores

| M√©trica | 1 R√©plica (0.5CPU) | 1 R√©plica (1.0CPU) | 2 R√©plicas (1.0CPU) | Mejora Total |
|---------|---------------------|---------------------|----------------------|--------------|
| **Total Requests** | 34,466 | 68,682 | **121,536** | **+252.6%** üöÄ |
| **RPS** | 287.8 | 574.3 | **1,015.3** | **+252.8%** üöÄ |
| **Tasa de Error** | 14.9% | 6.1% | **0.24%** | **-98.4%** ‚úÖ |
| **Failures** | 5,143 | 4,201 | **295** | **-94.3%** ‚úÖ |
| **Latencia P50** | 820ms | 400ms | **520ms** | **-36.6%** ‚úÖ |
| **Latencia P95** | 30,000ms | 17,000ms | **900ms** | **-97.0%** üéØ |
| **Latencia P99** | 69,000ms | 55,000ms | **1,100ms** | **-98.4%** üéØ |
| **CPU Total** | 0.5 | 1.0 | 2.0 | +300% |
| **Memoria Total** | 512MB | 1GB | 2GB | +292% |

#### An√°lisis

‚úÖ **EXITOSO - Cumple Objetivos del Taller**

- ‚úÖ Tasa de error: **0.24%** (objetivo: <1%) - **CUMPLIDO**
- ‚úÖ Latencia P95: **900ms** (objetivo: <1,000ms) - **CUMPLIDO**
- ‚úÖ Latencia P99: **1,100ms** (excelente)
- ‚úÖ RPS: **1,015 req/s** - **3.5x mejor que config inicial**
- ‚úÖ Endpoint GET / sin errores (0%)
- ‚úÖ POST /predict con solo 0.11% de errores
- ‚ö†Ô∏è GET /health a√∫n tiene 2.9% errores (posible mejora)

**Distribuci√≥n de Carga:**
- Docker DNS balance√≥ autom√°ticamente entre 2 r√©plicas
- Ambas r√©plicas mostraron uso similar de recursos (~50% CPU cada una)
- Sin hotspots ni desbalanceo significativo

**Conclusi√≥n:** El escalamiento horizontal con 2 r√©plicas es la **soluci√≥n √≥ptima** para este caso de uso.

---

## üìà An√°lisis de Resultados

### Gr√°fica Comparativa de Rendimiento

```
RPS (Requests Per Second)
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Exp 1 (0.5CPU, 1R)  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                288    ‚îÇ
‚îÇ Exp 2 (1.0CPU, 1R)  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà        574    ‚îÇ
‚îÇ Exp 3 (1.0CPU, 2R)  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 1,015  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                      +99%        +77%
```

```
Tasa de Error (%)
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Exp 1 (0.5CPU, 1R)  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà        14.9%   ‚îÇ
‚îÇ Exp 2 (1.0CPU, 1R)  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                  6.1%   ‚îÇ
‚îÇ Exp 3 (1.0CPU, 2R)  ‚ñå                       0.24%  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
          Objetivo: <1%  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚úì
```

```
Latencia P95 (ms)
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Exp 1 (0.5CPU, 1R)  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  30,000   ‚îÇ
‚îÇ Exp 2 (1.0CPU, 1R)  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    17,000   ‚îÇ
‚îÇ Exp 3 (1.0CPU, 2R)  ‚ñå                        900   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
          Objetivo: <1,000ms ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚úì
```

### An√°lisis de Costo-Beneficio

| Config | CPU | RAM | RPS | Error% | Costo Relativo | Eficiencia (RPS/CPU) |
|--------|-----|-----|-----|--------|----------------|----------------------|
| Exp 1 | 0.5 | 512MB | 288 | 14.9% | 1x | 576 |
| Exp 2 | 1.0 | 1GB | 574 | 6.1% | 2x | 574 |
| Exp 3 | 2.0 | 2GB | 1,015 | 0.24% | 4x | **507.5** |

**Observaci√≥n:** Aunque la eficiencia por CPU disminuye ligeramente con r√©plicas, la **mejora en confiabilidad y throughput** justifica el costo adicional.

### Tipos de Errores por Experimento

**Experimento 1:** Saturaci√≥n completa
- 55.7% ConnectionResetError en /predict
- 24.0% ConnectionResetError en /health
- 8.4% CatchResponseError (contenedor muri√≥)

**Experimento 2:** Sobrecarga intermitente
- 61.6% ConnectionResetError en /predict
- 30.1% ConnectionResetError en /health
- Menos timeouts (0.6% vs 11.1%)

**Experimento 3:** Estabilidad alcanzada
- Solo 295 errores totales (vs 5,143 y 4,201)
- Sin timeouts
- Sin status code 0
- Principalmente errores en /health (posible health check overhead)

### An√°lisis de Latencia

#### Percentiles de Latencia (ms)

| Config | P50 | P75 | P90 | P95 | P99 | P99.9 |
|--------|-----|-----|-----|-----|-----|-------|
| **Exp 1** | 820 | 1,100 | 18,000 | 30,000 | 69,000 | 97,000 |
| **Exp 2** | 400 | 540 | 740 | 17,000 | 55,000 | 112,000 |
| **Exp 3** | 520 | 680 | 820 | 900 | 1,100 | 107,000 |

**Insight:** Con 2 r√©plicas, el P95 y P99 mejoran dram√°ticamente, indicando que la mayor√≠a de las peticiones se sirven r√°pidamente y solo casos excepcionales tienen latencias altas.

---

## üéØ Conclusiones y Respuestas

### Respuestas a las Preguntas del Taller

#### 1. ¬øCu√°les son los recursos m√≠nimos necesarios?

**Para 1 R√©plica:**
```yaml
CPU: 1.0 core (m√≠nimo absoluto)
Memoria: 1024MB (1GB)
Resultado: 574 RPS, 6.1% errores (NO CUMPLE objetivo <1%)
```

**Para Cumplir Objetivos del Taller:**
```yaml
Configuraci√≥n: 2 R√©plicas
CPU por r√©plica: 1.0 core
Memoria por r√©plica: 1024MB
Total: 2.0 cores, 2GB RAM

Resultado: 1,015 RPS, 0.24% errores ‚úÖ
```

**Conclusi√≥n:** Los recursos m√≠nimos **absolutos** son 2.0 CPU + 2GB RAM en configuraci√≥n de 2 r√©plicas.

---

#### 2. ¬øEs posible reducir recursos con m√∫ltiples r√©plicas?

**Respuesta: NO, pero se obtiene mejor rendimiento y confiabilidad**

| Enfoque | Config | CPU Total | RAM Total | RPS | Error % | ¬øCumple? |
|---------|--------|-----------|-----------|-----|---------|----------|
| 1 r√©plica grande | 1.0 CPU | 1.0 | 1GB | 574 | 6.1% | ‚ùå |
| 2 r√©plicas medianas | 2x 1.0 CPU | 2.0 | 2GB | 1,015 | 0.24% | ‚úÖ |
| 2 r√©plicas peque√±as | 2x 0.5 CPU | 1.0 | 1GB | ~450* | ~8%* | ‚ùå |

*Estimado basado en tendencias observadas

**Trade-off:**
- üí∞ **Costo:** 2 r√©plicas requieren el doble de recursos totales
- ‚ö° **Rendimiento:** +77% m√°s RPS
- üõ°Ô∏è **Confiabilidad:** -96% menos errores
- üîÑ **Resiliencia:** Si 1 r√©plica falla, la otra contin√∫a

**Conclusi√≥n:** No se pueden reducir recursos totales con r√©plicas, pero se obtiene **mejor ROI** en t√©rminos de rendimiento y confiabilidad.

---

#### 3. ¬øCu√°l es la mayor cantidad de peticiones soportadas?

**M√°ximo Sostenido Encontrado:**

```
Configuraci√≥n: 2 r√©plicas, 1.0 CPU + 1GB cada una
RPS M√°ximo: 1,015 requests/segundo
Throughput: ~60,900 requests/minuto
Con: 99.76% de √©xito (0.24% errores)
```

**Extrapolaci√≥n:**

Si escalamos linealmente:
- 3 r√©plicas: ~1,500 RPS estimado
- 4 r√©plicas: ~2,000 RPS estimado

**L√≠mites Encontrados:**

- Con 0.5 CPU (1 r√©plica): ~288 RPS con 85% √©xito
- Con 1.0 CPU (1 r√©plica): ~574 RPS con 94% √©xito
- Con 2.0 CPU (2 r√©plicas): ~1,015 RPS con 99.76% √©xito

**Conclusi√≥n:** Con la configuraci√≥n √≥ptima encontrada, el sistema soporta **1,015 req/s de manera sostenida** con excelente confiabilidad.

---

#### 4. ¬øQu√© diferencia hay entre una o m√∫ltiples instancias?

### Comparaci√≥n Detallada

#### Una Instancia (1 R√©plica)

**‚úÖ Ventajas:**
- Configuraci√≥n m√°s simple
- Menos overhead de coordinaci√≥n
- Menor uso total de recursos (si no necesita escalar)
- M√°s f√°cil de debuggear (un solo proceso)
- Sesiones y estado m√°s f√°ciles de manejar

**‚ùå Desventajas:**
- Single Point of Failure (SPOF)
- Limitado por capacidad de 1 CPU
- No aprovecha paralelismo de m√∫ltiples cores
- Mayor latencia bajo carga (colas largas)
- Si falla, servicio completo cae

**üìä Rendimiento Observado:**
- RPS: 574
- Errores: 6.1%
- P95: 17 segundos
- Utilizaci√≥n CPU: ~95-100%

---

#### M√∫ltiples Instancias (2 R√©plicas)

**‚úÖ Ventajas:**
- Alta disponibilidad (si una falla, otra contin√∫a)
- Mejor distribuci√≥n de carga
- Aprovecha paralelismo
- Menor latencia individual por r√©plica
- Escalamiento horizontal f√°cil
- Mejor manejo de picos de tr√°fico
- Degradaci√≥n graceful (una r√©plica puede saturarse sin afectar a todas)

**‚ùå Desventajas:**
- Mayor complejidad operacional
- M√°s recursos totales requeridos
- Necesita load balancer (Docker DNS en nuestro caso)
- Sesiones stateful m√°s complejas de manejar
- Mayor costo de infraestructura

**üìä Rendimiento Observado:**
- RPS: 1,015 (+77%)
- Errores: 0.24% (-96%)
- P95: 900ms (-94%)
- Utilizaci√≥n CPU: ~50% cada r√©plica (mejor distribuci√≥n)

---

### Tabla Comparativa Final

| Aspecto | 1 R√©plica | 2 R√©plicas | Ganador |
|---------|-----------|------------|---------|
| **Throughput (RPS)** | 574 | 1,015 | üèÜ 2R (+77%) |
| **Confiabilidad** | 93.9% | 99.76% | üèÜ 2R |
| **Latencia P95** | 17s | 900ms | üèÜ 2R (-94%) |
| **Disponibilidad** | SPOF | Alta | üèÜ 2R |
| **Costo Recursos** | 1x | 2x | üèÜ 1R |
| **Complejidad** | Simple | Media | üèÜ 1R |
| **Escalabilidad** | Limitada | Alta | üèÜ 2R |
| **Resiliencia** | Baja | Alta | üèÜ 2R |

**Conclusi√≥n General:** Para producci√≥n con requisitos de alta disponibilidad y rendimiento, **m√∫ltiples r√©plicas son superiores** a pesar del mayor costo en recursos.

---

## üéì Lecciones Aprendidas

### 1. Escalamiento Vertical vs Horizontal

**Escalamiento Vertical (m√°s recursos por instancia):**
- Mejora rendimiento linealmente hasta cierto punto
- L√≠mite f√≠sico de una m√°quina
- Duplicar recursos (0.5‚Üí1.0 CPU) duplic√≥ RPS (288‚Üí574)
- Pero no fue suficiente para cumplir objetivos (<1% error)

**Escalamiento Horizontal (m√°s instancias):**
- Mejora rendimiento y confiabilidad simult√°neamente
- Sin l√≠mite te√≥rico (agregar m√°s r√©plicas)
- 2 r√©plicas lograron +77% RPS vs 1 r√©plica (con mismos recursos individuales)
- **Lecci√≥n:** Para APIs stateless, horizontal > vertical

### 2. Importancia de Health Checks

El endpoint `/health` tuvo m√°s errores relativamente:
- Exp 1: 49.3% de errores
- Exp 2: 27.6% de errores
- Exp 3: 2.9% de errores

**Raz√≥n:** Health checks frecuentes del Docker healthcheck + Locust crean overhead adicional.

**Recomendaci√≥n:** Configurar health checks con intervalos m√°s largos en producci√≥n.

### 3. Docker DNS Load Balancing

Docker DNS con round-robin funcion√≥ sorprendentemente bien:
- Distribuci√≥n equitativa (~50% cada r√©plica)
- Sin configuraci√≥n adicional requerida
- Sin necesidad de Nginx para este caso
- **Suficientemente bueno** para la mayor√≠a de casos

### 4. Importancia de Monitoreo

`docker stats` fue crucial para:
- Identificar r√©plicas saturadas
- Detectar l√≠mites de memoria
- Observar distribuci√≥n de carga
- Tomar decisiones sobre escalamiento

### 5. Errores de Conexi√≥n como Indicador

`ConnectionResetError` fue el **indicador clave** de saturaci√≥n:
- Alta tasa ‚Üí Recursos insuficientes
- Baja tasa ‚Üí Sistema saludable
- **M√©trica m√°s importante** que latencia promedio

---

## üöÄ Gu√≠a de Uso R√°pida

### Setup Inicial (Una Vez)

```bash
# 1. Entrenar modelo
make train

# 2. Construir imagen
make build

# 3. Publicar en DockerHub (opcional)
docker login
make push DOCKER_USER=tu-usuario
```

### Ejecutar Pruebas de Carga

```bash
# Iniciar con configuraci√≥n √≥ptima (2 r√©plicas)
make scale-load REPLICAS=2

# Abrir Locust
open http://localhost:8089

# Configurar en UI:
# - Users: 10000
# - Spawn rate: 500
# - Click "Start swarming"

# Monitorear (en otra terminal)
make stats
```

### Experimentos con Diferentes Configuraciones

```bash
# 1 r√©plica
make load

# 2 r√©plicas (√≥ptimo)
make scale-load REPLICAS=2

# 3 r√©plicas
make scale-load REPLICAS=3

# Detener
make stop
```

### Comandos √ötiles

```bash
# Ver todas las opciones
make help

# Ver r√©plicas activas
docker ps | grep api

# Logs de una r√©plica espec√≠fica
docker logs taller_locust-api-1

# Limpiar todo
make clean-all
```

---

## üìä Anexo: Datos Completos de Experimentos

### Experimento 1 - Datos Completos

```csv
Type,Request Count,Failure Count,Median RT,Avg RT,RPS,Failures/s
GET /,628,39,790.0,2063.7,5.2,0.33
GET /health,2810,1384,16000.0,17594.3,23.5,11.56
POST /predict,31028,3720,810.0,4043.2,259.1,31.07
Aggregated,34466,5143,820.0,5111.9,287.8,42.95
```

### Experimento 2 - Datos Completos

```csv
Type,Request Count,Failure Count,Median RT,Avg RT,RPS,Failures/s
GET /,1425,35,420.0,1006.4,11.9,0.29
GET /health,4581,1265,550.0,14397.3,38.3,10.58
POST /predict,62676,2901,390.0,1942.5,524.1,24.26
Aggregated,68682,4201,400.0,2753.8,574.3,35.13
```

### Experimento 3 - Datos Completos

```csv
Type,Request Count,Failure Count,Median RT,Avg RT,RPS,Failures/s
GET /,2450,0,530.0,537.1,20.5,0.0
GET /health,5936,172,550.0,6782.1,49.6,1.44
POST /predict,113150,123,520.0,784.8,945.2,1.03
Aggregated,121536,295,520.0,1072.7,1015.3,2.46
```

---

**Fecha de Finalizaci√≥n:** Octubre 13, 2025  
**Equipo:** MLOps Equipo 8  

---
