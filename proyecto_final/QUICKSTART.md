# GuÃ­a de Inicio RÃ¡pido - Proyecto Final MLOps

Esta guÃ­a proporciona instrucciones paso a paso para desplegar y probar el sistema completo de predicciÃ³n de precios inmobiliarios end-to-end.

## Requisitos Previos

Antes de comenzar, el usuario debe asegurarse de tener instalado:

- Docker 20.10+ y Docker Compose 2.0+
- 8 GB de RAM disponibles
- 20 GB de espacio en disco
- ConexiÃ³n a internet para descargar imÃ¡genes y datos

Para verificar las versiones:

```bash
docker --version
docker-compose --version
```

## PreparaciÃ³n del Entorno

### 1. Configurar Variables de Entorno

El usuario debe crear un archivo `.env` en la raÃ­z del proyecto con las siguientes variables:

```bash
# ConfiguraciÃ³n de PostgreSQL
POSTGRES_USER=mlops
POSTGRES_PASSWORD=mlops123
POSTGRES_DB_RAW=mlops_raw
POSTGRES_DB_CLEAN=mlops_clean
POSTGRES_DB_AIRFLOW=airflow_metadata
POSTGRES_DB_MLFLOW=mlflow_metadata

# Puertos de bases de datos
POSTGRES_PORT_RAW=5432
POSTGRES_PORT_CLEAN=5433
POSTGRES_PORT_AIRFLOW=5434
POSTGRES_PORT_MLFLOW=5435

# ConfiguraciÃ³n de Airflow
AIRFLOW_EXECUTOR=LocalExecutor
AIRFLOW_LOAD_EXAMPLES=False
AIRFLOW_ADMIN_USER=admin
AIRFLOW_ADMIN_PASSWORD=admin
AIRFLOW_ADMIN_EMAIL=admin@mlops.com

# ConfiguraciÃ³n de MLflow
MLFLOW_TRACKING_URI=http://mlflow:5000
MLFLOW_S3_ENDPOINT_URL=http://minio:9000
AWS_ACCESS_KEY_ID=minioadmin
AWS_SECRET_ACCESS_KEY=minioadmin

# ConfiguraciÃ³n de MinIO
MINIO_ROOT_USER=minioadmin
MINIO_ROOT_PASSWORD=minioadmin
MINIO_BUCKET=mlflow

# ConfiguraciÃ³n de API Externa
API_BASE_URL=http://10.43.100.103:8000
GROUP_NUMBER=3

# Puertos de servicios
AIRFLOW_PORT=8080
MLFLOW_PORT=5000
API_PORT=8000
FRONTEND_PORT=8501
PROMETHEUS_PORT=9090
GRAFANA_PORT=3000
LOCUST_PORT=8089
MINIO_API_PORT=9000
MINIO_CONSOLE_PORT=9001
```

### 2. Verificar la API Externa

Antes de iniciar, el usuario debe verificar que la API de datos estÃ© disponible:

```bash
curl http://10.43.100.103:8000/health
```

Si la API no estÃ¡ disponible, el DAG de ingesta fallarÃ¡.

## Flujo de EjecuciÃ³n Completo

### Paso 1: Levantar Infraestructura Base

El usuario debe iniciar las bases de datos y servicios de almacenamiento:

```bash
docker-compose up -d postgres-raw postgres-clean postgres-airflow postgres-mlflow minio
```

Se debe esperar aproximadamente 30 segundos para que las bases de datos estÃ©n listas. Para verificar el estado:

```bash
docker-compose ps
```

Se deberÃ­an observar 5 servicios con estado "Up".

### Paso 2: Iniciar MLflow y Airflow

Se deben levantar los servicios de orquestaciÃ³n y tracking:

```bash
docker-compose up -d mlflow airflow-webserver
```

Se debe esperar 1-2 minutos para que Airflow complete su inicializaciÃ³n. Para verificar el acceso:

- Airflow: http://localhost:8080 (usuario: admin, contraseÃ±a: admin)
- MLflow: http://localhost:5000

### Paso 3: Ejecutar DAG de Ingesta

Desde la interfaz de Airflow (http://localhost:8080), el usuario debe:

1. Ir a la secciÃ³n "DAGs"
2. Buscar el DAG `1_ingest_from_external_api`
3. Activar el toggle (ON) en la columna izquierda
4. Hacer clic en el botÃ³n "Trigger DAG" (play button)
5. Monitorear el progreso en la vista "Graph"

El DAG tomarÃ¡ aproximadamente 5-10 minutos dependiendo del volumen de datos.

**ValidaciÃ³n**:

```bash
# Conectarse a la base RAW
docker exec -it postgres-raw psql -U mlops -d mlops_raw -c "SELECT COUNT(*) FROM raw_train;"
```

Se deberÃ­an observar registros insertados (ej. 1000+ registros).

### Paso 4: Ejecutar DAG de Preprocesamiento

Una vez completado el DAG de ingesta, el usuario debe:

1. En Airflow, buscar el DAG `2_clean_build`
2. Activarlo y ejecutarlo manualmente (Trigger DAG)
3. Este DAG tomarÃ¡ 3-5 minutos

El DAG aplicarÃ¡ feature engineering y normalizarÃ¡ los datos.

**ValidaciÃ³n**:

```bash
# Conectarse a la base CLEAN
docker exec -it postgres-clean psql -U mlops -d mlops_clean -c "SELECT COUNT(*) FROM clean_train;"
```

Se deberÃ­a observar el mismo nÃºmero de registros con 30+ columnas.

### Paso 5: Ejecutar DAG de Entrenamiento

Con los datos limpios disponibles, el usuario debe:

1. En Airflow, buscar el DAG `3_train_and_register`
2. Activarlo y ejecutarlo manualmente
3. Este DAG tomarÃ¡ 10-15 minutos (entrena 3 modelos)

El mejor modelo serÃ¡ promovido automÃ¡ticamente a stage "Production" en MLflow.

**ValidaciÃ³n**:

El usuario debe acceder a MLflow (http://localhost:5000) y:

1. Hacer clic en "Models" en la barra superior
2. Se deberÃ­a observar el modelo registrado (ej. "realtor_model")
3. Hacer clic en el modelo y verificar que hay una versiÃ³n en stage "Production"

### Paso 6: Levantar API y Frontend

Ahora que hay un modelo en producciÃ³n, se deben levantar los servicios de inferencia:

```bash
docker-compose up -d api frontend
```

Se debe esperar 30-60 segundos para que carguen. Para verificar el acceso:

- API: http://localhost:8000
- Frontend: http://localhost:8501

**ValidaciÃ³n de API**:

```bash
# Health check
curl http://localhost:8000/health

# InformaciÃ³n del modelo
curl http://localhost:8000/model-info
```

Se deberÃ­an observar respuestas JSON con status 200.

**ValidaciÃ³n de Frontend**:

1. Abrir http://localhost:8501 en el navegador
2. DeberÃ­a aparecer la interfaz con 4 tabs
3. En el sidebar, verificar que muestre "API Status: Connected"
4. Verificar que muestre informaciÃ³n del modelo en producciÃ³n

### Paso 7: Realizar PredicciÃ³n

#### OpciÃ³n A: Desde el Frontend (Recomendado)

1. Acceder a http://localhost:8501
2. En el Tab 1 "PredicciÃ³n Individual", completar el formulario:
   - Brokered By: Century 21
   - Status: for_sale
   - Bed: 3
   - Bath: 2
   - Acre Lot: 0.25
   - Street: 123 Main St
   - City: Miami
   - State: Florida
   - Zip Code: 33101
   - House Size: 1500
   - Previous Sold Date: 2020-01-15
3. Hacer clic en "Predecir Precio"
4. Verificar que muestre un precio estimado

#### OpciÃ³n B: Desde la API (curl)

```bash
curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d '{
    "brokered_by": "Century 21",
    "status": "for_sale",
    "bed": 3,
    "bath": 2,
    "acre_lot": 0.25,
    "street": "123 Main St",
    "city": "Miami",
    "state": "Florida",
    "zip_code": "33101",
    "house_size": 1500,
    "prev_sold_date": "2020-01-15"
  }'
```

Respuesta esperada:

```json
{
  "predicted_price": 345678.90,
  "model_name": "realtor_model",
  "model_version": "1",
  "model_stage": "Production"
}
```

### Paso 8: Explorar Explicabilidad SHAP

1. En el Frontend, acceder al Tab 3 "Explicabilidad SHAP"
2. Completar el formulario con los mismos datos del paso 7
3. Hacer clic en "Generar ExplicaciÃ³n"
4. Verificar que aparezcan:
   - GrÃ¡fico Waterfall (top 15 features mÃ¡s importantes)
   - GrÃ¡fico Force (impacto positivo/negativo)
   - Tabla con valores SHAP ordenados

Esto permite comprender quÃ© features contribuyeron mÃ¡s a la predicciÃ³n.

### Paso 9: Monitorear con Grafana

Se deben levantar los servicios de observabilidad:

```bash
docker-compose up -d prometheus grafana
```

Para acceder a Grafana, el usuario debe:

1. Ir a http://localhost:3000
2. Usuario: admin, ContraseÃ±a: admin
3. Si solicita cambiar contraseÃ±a, se puede omitir
4. Ir a "Configuration" â†’ "Data Sources"
5. Verificar que Prometheus estÃ© configurado (http://prometheus:9090)
6. Ir a "Dashboards" â†’ "Browse" y explorar los dashboards predefinidos

**MÃ©tricas disponibles**:

- Total de requests a la API
- Latencia de predicciones (P50, P95, P99)
- Predicciones por minuto
- Errores HTTP

### Paso 10: Pruebas de Carga con Locust

Se debe levantar Locust para simular trÃ¡fico:

```bash
docker-compose up -d locust
```

Para acceder a Locust, el usuario debe:

1. Ir a http://localhost:8089
2. Configurar:
   - Number of users: 10
   - Spawn rate: 2
   - Host: http://api:8000
3. Hacer clic en "Start swarming"
4. Monitorear las mÃ©tricas en tiempo real:
   - RPS (Requests Per Second)
   - Response Time (ms)
   - Failure Rate

**DuraciÃ³n recomendada**: 5 minutos

**ValidaciÃ³n**:

Mientras Locust estÃ¡ ejecutÃ¡ndose, el usuario debe ir a Grafana y observar cÃ³mo aumentan las mÃ©tricas de la API.

## Comandos Ãštiles

### Ver logs de un servicio

```bash
# Logs de Airflow
docker-compose logs -f airflow-webserver

# Logs de API
docker-compose logs -f api

# Logs de MLflow
docker-compose logs -f mlflow

# Logs de un DAG especÃ­fico (desde dentro del contenedor de Airflow)
docker exec -it airflow-webserver cat /opt/airflow/logs/dag_id=1_ingest_from_external_api/run_id=manual__2024-11-20T10:00:00/task_id=fetch_data_from_api/attempt=1.log
```

### Reiniciar un servicio

```bash
docker-compose restart <servicio>
```

### Detener todos los servicios

```bash
docker-compose down
```

### Detener y eliminar volÃºmenes (reinicio completo)

```bash
docker-compose down -v
```

**Advertencia**: Esto eliminarÃ¡ todas las bases de datos y modelos entrenados.

### Conectarse a una base de datos

```bash
# Base RAW
docker exec -it postgres-raw psql -U mlops -d mlops_raw

# Base CLEAN
docker exec -it postgres-clean psql -U mlops -d mlops_clean

# Base MLflow
docker exec -it postgres-mlflow psql -U mlops -d mlflow_metadata
```

### Verificar estado de todos los servicios

```bash
docker-compose ps
```

### Ver uso de recursos

```bash
docker stats
```

### Ejecutar tests automatizados

```bash
# Tests de la API
docker-compose run --rm api pytest /app/tests/

# Tests del pipeline completo
docker-compose run --rm airflow-webserver pytest /opt/airflow/tests/
```

## Troubleshooting

### Problema: Airflow no arranca

**SÃ­ntoma**: El contenedor `airflow-webserver` se reinicia constantemente.

**SoluciÃ³n**:

```bash
# Ver logs
docker-compose logs airflow-webserver

# Verificar que la base de datos de Airflow estÃ© lista
docker exec -it postgres-airflow psql -U mlops -d airflow_metadata -c "\dt"

# Si la base estÃ¡ vacÃ­a, reinicializar
docker-compose down
docker-compose up -d postgres-airflow
docker-compose up -d airflow-webserver
```

### Problema: DAG de ingesta falla

**SÃ­ntoma**: DAG `1_ingest_from_external_api` falla en la tarea `fetch_data_from_api`.

**SoluciÃ³n**:

```bash
# Verificar conectividad con la API externa
docker exec -it airflow-webserver curl http://10.43.100.103:8000/health

# Si no hay conectividad, revisar la variable GROUP_NUMBER en .env
# Verificar logs del DAG
docker-compose logs airflow-webserver | grep "ingest_from_external_api"
```

### Problema: API no carga el modelo

**SÃ­ntoma**: `curl http://localhost:8000/health` retorna `model_loaded: false`.

**SoluciÃ³n**:

```bash
# Verificar que hay un modelo en Production en MLflow
curl http://localhost:5000/api/2.0/mlflow/registered-models/search

# Si no hay modelo, ejecutar DAG 3 primero
# Si hay modelo, reiniciar API
docker-compose restart api
docker-compose logs -f api
```

### Problema: Frontend no se conecta a la API

**SÃ­ntoma**: En el frontend, el sidebar muestra "API Status: Disconnected".

**SoluciÃ³n**:

```bash
# Verificar que la API estÃ© levantada
curl http://localhost:8000/health

# Verificar que el frontend pueda alcanzar la API (desde dentro del contenedor)
docker exec -it frontend curl http://api:8000/health

# Si falla, revisar la red de Docker
docker network inspect proyecto_final_default
```

### Problema: MinIO no accesible

**SÃ­ntoma**: MLflow falla al guardar artefactos con error "Unable to connect to endpoint".

**SoluciÃ³n**:

```bash
# Verificar que MinIO estÃ© levantado
docker-compose ps minio

# Crear bucket manualmente si no existe
docker exec -it minio mc alias set local http://localhost:9000 minioadmin minioadmin
docker exec -it minio mc mb local/mlflow

# Reiniciar MLflow
docker-compose restart mlflow
```

### Problema: Locust no puede alcanzar la API

**SÃ­ntoma**: Locust muestra 100% de errores de conexiÃ³n.

**SoluciÃ³n**:

```bash
# Verificar que Locust y API estÃ©n en la misma red
docker network inspect proyecto_final_default | grep -E "locust|api"

# En la UI de Locust, asegÃºrate de usar http://api:8000 (nombre del servicio, no localhost)
```

### Problema: Prometheus no recolecta mÃ©tricas

**SÃ­ntoma**: En Grafana, las grÃ¡ficas estÃ¡n vacÃ­as.

**SoluciÃ³n**:

```bash
# Verificar que Prometheus pueda alcanzar la API
docker exec -it prometheus wget -O- http://api:8000/metrics

# Revisar configuraciÃ³n de Prometheus
docker exec -it prometheus cat /etc/prometheus/prometheus.yml

# Verificar targets en Prometheus UI
# Ve a http://localhost:9090/targets
```

### Problema: Memoria insuficiente

**SÃ­ntoma**: Los servicios se matan con cÃ³digo 137 (OOM Killed).

**SoluciÃ³n**:

```bash
# Ver uso de memoria
docker stats

# Aumentar memoria disponible para Docker Desktop
# Settings â†’ Resources â†’ Memory â†’ 8 GB mÃ­nimo

# Alternativamente, levantar servicios por partes
docker-compose up -d postgres-raw postgres-clean
docker-compose up -d airflow-webserver mlflow
# ... esperar entre grupos
```

## Checklist de ValidaciÃ³n End-to-End

El usuario puede utilizar este checklist para verificar que todo funciona correctamente:

- [ ] **Infraestructura Base**
  - [ ] 4 bases de datos PostgreSQL levantadas y accesibles
  - [ ] MinIO levantado y bucket `mlflow` creado

- [ ] **Airflow**
  - [ ] Airflow UI accesible en http://localhost:8080
  - [ ] 3 DAGs visibles: ingesta, preprocesamiento, entrenamiento

- [ ] **Pipeline de Datos**
  - [ ] DAG 1 ejecutado con Ã©xito (datos en raw_train)
  - [ ] DAG 2 ejecutado con Ã©xito (datos en clean_train con 30+ columnas)
  - [ ] DAG 3 ejecutado con Ã©xito (modelo registrado en MLflow)

- [ ] **MLflow**
  - [ ] MLflow UI accesible en http://localhost:5000
  - [ ] Al menos 1 experimento con 3 runs (3 modelos entrenados)
  - [ ] Modelo en stage "Production" visible en Model Registry

- [ ] **API de Inferencia**
  - [ ] API responde en http://localhost:8000
  - [ ] `/health` retorna `model_loaded: true`
  - [ ] `/model-info` retorna versiÃ³n del modelo en Production
  - [ ] `/predict` retorna predicciÃ³n vÃ¡lida (nÃºmero positivo)

- [ ] **Frontend**
  - [ ] Frontend accesible en http://localhost:8501
  - [ ] Sidebar muestra "API Status: Connected"
  - [ ] Tab 1 permite hacer predicciÃ³n individual
  - [ ] Tab 2 permite cargar CSV y descargar resultados
  - [ ] Tab 3 muestra grÃ¡ficos SHAP correctamente

- [ ] **Observabilidad**
  - [ ] Prometheus accesible en http://localhost:9090
  - [ ] Grafana accesible en http://localhost:3000
  - [ ] Grafana muestra mÃ©tricas de la API

- [ ] **Pruebas de Carga**
  - [ ] Locust accesible en http://localhost:8089
  - [ ] Locust puede ejecutar pruebas contra la API
  - [ ] MÃ©tricas en Grafana reflejan trÃ¡fico de Locust

## Notas sobre Kubernetes

Si se desea desplegar en Kubernetes en lugar de Docker Compose:

1. **Crear el namespace**:

```bash
kubectl apply -f kubernetes/namespace.yaml
```

2. **Crear PersistentVolumeClaims**:

```bash
kubectl apply -f kubernetes/pvc.yaml
```

3. **Desplegar bases de datos**:

```bash
kubectl apply -f kubernetes/databases.yaml
```

4. **Desplegar MLflow**:

```bash
kubectl apply -f kubernetes/mlflow.yaml
```

5. **Desplegar Airflow, API y Frontend**:

```bash
kubectl apply -f kubernetes/api.yaml
kubectl apply -f kubernetes/frontend.yaml
```

6. **Configurar Argo CD para GitOps**:

```bash
kubectl create namespace argocd
kubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml

# Esperar a que Argo CD estÃ© listo
kubectl wait --for=condition=available --timeout=300s deployment/argocd-server -n argocd

# Aplicar Project y Applications
kubectl apply -f argocd/project.yaml
kubectl apply -f argocd/applications.yaml
```

7. **Acceder a servicios**:

```bash
# Port-forward de Airflow
kubectl port-forward -n mlops svc/airflow 8080:8080

# Port-forward de MLflow
kubectl port-forward -n mlops svc/mlflow 5000:5000

# Port-forward de API
kubectl port-forward -n mlops svc/api 8000:8000

# Port-forward de Frontend
kubectl port-forward -n mlops svc/frontend 8501:8501
```

**Nota**: Los manifiestos de Kubernetes asumen que el usuario tiene un cluster funcional. Para desarrollo local, se recomienda usar Minikube o Kind.

## Monitoreo de GitHub Actions (CI/CD)

### Â¿QuÃ© son los GitHub Actions y para quÃ© sirven?

GitHub Actions **NO reemplazan** Docker Compose. Son herramientas complementarias:

- **GitHub Actions**: Construye y publica imÃ¡genes Docker automÃ¡ticamente cuando se hace `git push`
- **Docker Compose**: Levanta y ejecuta los servicios en la mÃ¡quina local o servidor

**AnalogÃ­a**: GitHub Actions es una fÃ¡brica que construye productos (imÃ¡genes Docker), mientras que Docker Compose es el lugar donde se usan esos productos (ejecuta los contenedores).

### Â¿CuÃ¡ndo se ejecutan los workflows?

Los workflows de GitHub Actions se activan automÃ¡ticamente cuando:

1. Se hace `git push` a las ramas `main` o `master`
2. Se crea o actualiza un Pull Request
3. Se modifican archivos especÃ­ficos (ej. `dags/**`, `services/api/**`)

### CÃ³mo Ver las Ejecuciones de GitHub Actions

Si el proyecto estÃ¡ en GitHub, se puede monitorear las ejecuciones de los workflows:

#### Paso 1: Acceder a la PestaÃ±a Actions

1. Acceder al repositorio en GitHub: `https://github.com/usuario/proyecto-final-mlops`
2. Hacer clic en la pestaÃ±a **"Actions"** en la parte superior
3. Se observarÃ¡ una lista de todas las ejecuciones recientes

#### Paso 2: Explorar una EjecuciÃ³n EspecÃ­fica

1. Hacer clic en cualquier ejecuciÃ³n de la lista (ej. "Build Airflow Image")
2. Se observarÃ¡ el estado:
   - âœ… **Verde (Success)**: La imagen se construyÃ³ y publicÃ³ correctamente
   - âŒ **Rojo (Failure)**: Hubo errores en build, tests o linting
   - ğŸŸ¡ **Amarillo (In Progress)**: AÃºn estÃ¡ ejecutÃ¡ndose
   - âšª **Gris (Cancelled)**: Se cancelÃ³ manualmente

3. Hacer clic en el nombre del job (ej. "build")
4. Se desplegarÃ¡ cada paso del workflow:
   - Checkout code
   - Set up Docker Buildx
   - Login to DockerHub
   - Build and push
   - etc.

5. Hacer clic en cualquier paso para ver los logs detallados

#### Paso 3: Verificar ImÃ¡genes Publicadas en DockerHub

DespuÃ©s de una ejecuciÃ³n exitosa:

1. Acceder a DockerHub: `https://hub.docker.com/r/usuario/`
2. Se deberÃ­an observar los repositorios:
   - `usuario/proyecto-final-airflow`
   - `usuario/proyecto-final-api`
   - `usuario/proyecto-final-frontend`
   - `usuario/proyecto-final-mlflow`

3. Hacer clic en uno de los repositorios
4. En la pestaÃ±a "Tags", se observarÃ¡n las etiquetas:
   - `latest`: Ãšltima versiÃ³n construida
   - `sha-abc123`: VersiÃ³n especÃ­fica del commit

#### Paso 4: Usar las ImÃ¡genes Publicadas

Para usar las imÃ¡genes construidas por GitHub Actions en el `docker-compose.yml`:

```yaml
# Antes (build local)
services:
  airflow-webserver:
    build:
      context: ./dags
      dockerfile: Dockerfile.airflow

# DespuÃ©s (usar imagen de DockerHub)
services:
  airflow-webserver:
    image: usuario/proyecto-final-airflow:latest
```

Luego se debe ejecutar:

```bash
# Descargar Ãºltima imagen desde DockerHub
docker-compose pull airflow-webserver

# Reiniciar con la nueva imagen
docker-compose up -d airflow-webserver
```

### QuÃ© Validan los Workflows

Cada workflow ejecuta diferentes validaciones:

#### Workflow CI (`ci.yml`)
**Se ejecuta en**: Todos los pushes y PRs

**Validaciones**:
```bash
# 1. Tests unitarios
pytest tests/ --cov --cov-report=xml

# 2. Linting de cÃ³digo (estilo)
flake8 dags/ services/ --max-line-length=120

# 3. Escaneo de seguridad
bandit -r dags/ services/ -f json -o bandit-report.json

# 4. VerificaciÃ³n de tipos (opcional)
mypy dags/ --ignore-missing-imports
```

**Si falla**: No se construyen las imÃ¡genes Docker

#### Workflows de Build (Airflow, API, Frontend, MLflow)
**Se ejecuta en**: Pushes a main/master que modifican archivos relevantes

**Acciones**:
```bash
# 1. Construir imagen Docker
docker build -t usuario/proyecto-final-airflow:latest -f dags/Dockerfile.airflow .

# 2. Etiquetar con SHA del commit
docker tag usuario/proyecto-final-airflow:latest usuario/proyecto-final-airflow:sha-abc123

# 3. Publicar a DockerHub
docker push usuario/proyecto-final-airflow:latest
docker push usuario/proyecto-final-airflow:sha-abc123
```

**Si falla**: La imagen no se publica, el equipo no podrÃ¡ usar la nueva versiÃ³n

### Configurar Secrets en GitHub

Para que los workflows funcionen, el usuario debe configurar secrets:

1. Acceder al repositorio en GitHub
2. Settings â†’ Secrets and variables â†’ Actions
3. Hacer clic en "New repository secret"
4. Agregar estos secrets:

   - **DOCKERHUB_USERNAME**: Usuario de DockerHub
   - **DOCKERHUB_TOKEN**: Token de acceso de DockerHub
     - Para crear el token: DockerHub â†’ Account Settings â†’ Security â†’ New Access Token

### Troubleshooting de GitHub Actions

#### Problema: Workflow falla en "Login to DockerHub"

**Causa**: Secrets no configurados o incorrectos

**SoluciÃ³n**:
```bash
# Verificar que los secrets existan
# Settings â†’ Secrets and variables â†’ Actions

# Crear nuevo token en DockerHub si es necesario
# DockerHub â†’ Account Settings â†’ Security â†’ New Access Token
```

#### Problema: Workflow falla en tests

**Causa**: CÃ³digo con errores de sintaxis o tests que no pasan

**SoluciÃ³n**:
```bash
# Ejecutar tests localmente antes de push
cd proyecto_final
pip install -r tests/requirements.txt
pytest tests/ -v

# Corregir errores y volver a hacer commit
```

#### Problema: Workflow falla en build de imagen

**Causa**: Dockerfile con errores o dependencias no disponibles

**SoluciÃ³n**:
```bash
# Probar build localmente
docker build -t test-airflow -f dags/Dockerfile.airflow .

# Ver logs detallados
docker build --progress=plain -t test-airflow -f dags/Dockerfile.airflow .
```

#### Problema: Workflow queda "stuck" en ejecuciÃ³n

**Causa**: Comando bloqueante o timeout largo

**SoluciÃ³n**:
```bash
# Cancelar la ejecuciÃ³n desde GitHub UI
# Actions â†’ Click en la ejecuciÃ³n â†’ Cancel workflow

# Revisar el Ãºltimo paso donde se quedÃ³
# Ajustar timeouts en el workflow si es necesario
```

### Comandos Ãštiles para CI/CD

```bash
# Ver historial de imÃ¡genes locales
docker images | grep proyecto-final

# Limpiar imÃ¡genes antiguas
docker image prune -a

# Descargar Ãºltima versiÃ³n de todas las imÃ¡genes
docker-compose pull

# Reconstruir y reiniciar todos los servicios
docker-compose up -d --build

# Ver quÃ© imagen estÃ¡ usando cada contenedor
docker-compose ps --format "table {{.Name}}\t{{.Image}}\t{{.Status}}"

# Forzar recreaciÃ³n de contenedores con nueva imagen
docker-compose up -d --force-recreate
```

### Flujo Recomendado de Trabajo

1. **Desarrollo local**: Realizar cambios en el cÃ³digo
2. **Prueba local**: `docker-compose restart <servicio>` para probar
3. **Commit y push**: `git add . && git commit -m "mensaje" && git push`
4. **Monitorear Actions**: Acceder a GitHub Actions y verificar que pase
5. **Esperar publicaciÃ³n**: Esperar a que la imagen se publique en DockerHub (2-5 min)
6. **Actualizar localmente**: `docker-compose pull <servicio> && docker-compose up -d <servicio>`
7. **Validar cambios**: Verificar que los cambios funcionen correctamente

### Diferencia Clave: Build vs Run

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                      GitHub Actions                           â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â•‘
â•‘  â”‚  FASE: BUILD (ConstrucciÃ³n)                        â”‚      â•‘
â•‘  â”‚  - Toma cÃ³digo fuente                              â”‚      â•‘
â•‘  â”‚  - Ejecuta tests                                   â”‚      â•‘
â•‘  â”‚  - Construye imagen Docker                         â”‚      â•‘
â•‘  â”‚  - Publica a DockerHub                             â”‚      â•‘
â•‘  â”‚  OUTPUT: Imagen lista para usar                    â”‚      â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                           â”‚
                           â”‚ docker pull
                           â–¼
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                      Docker Compose                           â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â•‘
â•‘  â”‚  FASE: RUN (EjecuciÃ³n)                             â”‚      â•‘
â•‘  â”‚  - Descarga imagen de DockerHub                    â”‚      â•‘
â•‘  â”‚  - Crea contenedor                                 â”‚      â•‘
â•‘  â”‚  - Expone puertos                                  â”‚      â•‘
â•‘  â”‚  - Monta volÃºmenes                                 â”‚      â•‘
â•‘  â”‚  - Conecta a redes                                 â”‚      â•‘
â•‘  â”‚  - MANTIENE SERVICIO CORRIENDO                     â”‚      â•‘
â•‘  â”‚  OUTPUT: Servicio accesible en http://localhost    â”‚      â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

**AnalogÃ­a Final**:
- **GitHub Actions**: FÃ¡brica de coches (construye el producto)
- **DockerHub**: Concesionario (almacena los productos)
- **Docker Compose**: Conductor (usa el coche para ir a lugares)

No se puede conducir un coche que solo estÃ¡ en la fÃ¡brica, y no se puede construir un coche nuevo cada vez que se desee ir a algÃºn lugar. Ambos son necesarios pero en diferentes momentos.

## PrÃ³ximos Pasos

Una vez completada esta guÃ­a, el usuario puede:

1. **Explorar MLflow**: Revisar experimentos, comparar modelos, analizar mÃ©tricas
2. **Personalizar dashboards de Grafana**: Crear alertas y visualizaciones custom
3. **Optimizar modelos**: Modificar hiperparÃ¡metros en el DAG de entrenamiento
4. **Agregar features**: Implementar nuevas transformaciones en el DAG de preprocesamiento
5. **Implementar A/B testing**: Tener dos versiones de modelo en Staging y Production
6. **Configurar CI/CD**: Conectar GitHub Actions con el repositorio para deployments automÃ¡ticos
7. **Explorar Argo CD**: Desplegar en Kubernetes con GitOps
8. **Monitorear GitHub Actions**: Configurar notificaciones de Slack/Email cuando los builds fallen
9. **Implementar workflow de release**: Crear tags y releases automÃ¡ticas cuando se actualice la versiÃ³n

## Soporte

Si se encuentran problemas no cubiertos en esta guÃ­a:

1. Revisar los logs detallados de cada servicio
2. Consultar la documentaciÃ³n adicional en `docs/`
3. Revisar el archivo `COMPONENTES_IMPLEMENTADOS.md` para detalles tÃ©cnicos
4. Contactar al equipo del proyecto

---

**Ãšltima actualizaciÃ³n**: Noviembre 2024  
**VersiÃ³n**: 1.0
